{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "import mediapipe as mp\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm\n",
    "from skimage.morphology import convex_hull_image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import cv2\n",
    "# from PIL import Image\n",
    "from os import listdir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compress images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compress_image(path : str):\n",
    "# \tim = Image.open(path)\n",
    "# \tim.thumbnail((500, 500), Image.LANCZOS)\n",
    "# \tim.save(path.replace('dataset', 'reduced_dataset'))\n",
    "\n",
    "# def compress_dataset(path : str):\n",
    "# \tfor num in range(0,6):\n",
    "# \t\tmen_dir = path + f'men/{num}/'\n",
    "# \t\twomen_dir = path + f'Women/{num}/'\n",
    "# \t\tfor file in listdir(men_dir):\n",
    "# \t\t\tcompress_image(men_dir + file)\n",
    "# \t\tfor file in listdir(women_dir):\n",
    "# \t\t\tcompress_image(women_dir + file)\n",
    "\n",
    "# compress_dataset('../../dataset/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path: str) -> np.array:\n",
    "\timg = cv2.imread(path)\n",
    "\t# img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\t# dx = cv2.Sobel(img_gray,cv2.CV_64F,1,0,ksize=9)\n",
    "\t# dy = cv2.Sobel(img_gray,cv2.CV_64F,0,1,ksize=9)\n",
    "\t# mag, angle = cv2.cartToPolar(dx,dy,angleInDegrees=True)\n",
    "\t# # mag *= 255.0/np.max(mag)\n",
    "\t# hist_bin = np.zeros((12,))\n",
    "\t# for i in range(0,12):\n",
    "\t# \thist_bin[i] = np.sum(mag[(angle>=i*30) & (angle<(i+1)*30)])\n",
    "\t# # hist_bin *= 1/np.max(hist_bin)\n",
    "\t# hist_bin = np.sum(hist_bin.reshape((-1,2)), axis=1)\n",
    "\n",
    "\timg = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)\n",
    "\tavg_luma = np.mean(img[:,:,0])\n",
    "\tif avg_luma>196:\n",
    "\t\timg = cv2.inRange(img,(0,133,77),(255,163,140))\n",
    "\telse:\n",
    "\t\timg = cv2.inRange(img,(0,137,77),(255,163,140))\n",
    "\tblur = cv2.medianBlur(img, 5)\n",
    "\tkernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (8, 8))\n",
    "\timg_filtered = cv2.dilate(blur, kernel)\n",
    "\tctrs, _ = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "\tmax_ctr = max(ctrs,key=cv2.contourArea)\n",
    "\thullpts = np.zeros((40,2))\n",
    "\thull = cv2.convexHull(max_ctr)\n",
    "\tcontour = np.zeros(img.shape)\n",
    "\t\n",
    "\tcv2.drawContours(contour,hull,-1,(255,255,255),1)\n",
    "\tcontour = convex_hull_image(contour)\n",
    "\tcontour = np.asarray(hull,dtype=int)\n",
    "\tcontour = np.sum(contour)\n",
    "\thull = hull.reshape(-1,2)\n",
    "\thullpts[:hull.shape[0],:] = hull\n",
    "\t# img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\t# dx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=1)\n",
    "\t# dy = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=1)\n",
    "\t# img_filtered = np.hypot(dx,dy)\n",
    "\t# img_filtered *= 255.0/np.max(img_filtered)\n",
    "\t# img_filtered = cv2.threshold(img_filtered,thresh=50,maxval=255,type=cv2.THRESH_BINARY)[1]\n",
    "\t# histogramV = np.array([np.mean(np.sum(img_filtered,axis=0))])\n",
    "\t# img = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)\n",
    "\t# img = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)\n",
    "\t# img_gray = cv2.inRange(cv2.cvtColor(img,cv2.COLOR_BGR2GRAY),0,128)\n",
    "\t# brightness_coeff = (np.mean(img_gray)/255 - 0.015)*10.25\n",
    "\t# img_filtered = cv2.inRange(img,(0,int(133+brightness_coeff),77),(255,163,140))\n",
    "\t# print(img_filtered_cluttered[5][0])\n",
    "\t# img = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "\t# img_masked_shadow = np.bitwise_not(cv2.inRange(img,(0,0,80),(255,55,179)))\n",
    "\t# img_masked_hand = cv2.inRange(img,(5,35,30),(25,255,255))\n",
    "\t# img_filtered = np.bitwise_and(img_masked_shadow,img_masked_hand)\n",
    "\t# area = np.array([np.sum(img_filtered.reshape((-1))) / 255])\n",
    "\t# bucket_size = 10\n",
    "\t# img_filtered_cluttered = img_filtered[1:,:].reshape((int(img_filtered[1:,:].shape[0]/bucket_size),-1,bucket_size))\n",
    "\t# histogramH = np.array([np.mean(np.diff(np.sum(img_filtered_cluttered,axis=(1,2))))])\n",
    "\t# # print(histogramH.dtype)\n",
    "\n",
    "\t# img_filtered_cluttered = img_filtered.reshape((-1,int(img_filtered.shape[1]/bucket_size),bucket_size))\n",
    "\treturn np.concatenate((hullpts[:,0],hullpts[:,1],[contour],img_filtered.reshape(-1)), dtype=np.float32)\n",
    "\t# return np.concatenate((hullpts[:,0],hullpts[:,1],[contour],hist_bin,img_filtered.reshape(-1)))\n",
    "\n",
    "def read_images(directory : str) -> np.array:\n",
    "\tarray = np.array([], dtype=np.float32).reshape(0, 140582)\n",
    "\tfor num in range(0,6):\n",
    "\t\t# if num == 3 or num == 4:\n",
    "\t\t# \tmen_dir = directory + f'men/{num}/'\n",
    "\t\t# \twomen_dir = directory + f'Women/{num}/'\n",
    "\t\t# \tnew_men = np.array([np.concatenate((np.asarray([num]), read_image(men_dir + file)), axis=0) for file in listdir(men_dir)])\n",
    "\t\t# \tnew_women = np.array([np.concatenate((np.asarray([num]), read_image(women_dir + file)), axis=0) for file in listdir(women_dir)])\n",
    "\t\t# \tarray = np.concatenate((array, new_men, new_women), axis=0)\n",
    "\t\tmen_dir = directory + f'men/{num}/'\n",
    "\t\twomen_dir = directory + f'Women/{num}/'\n",
    "\t\tnew_men = np.array([np.concatenate((np.asarray([num]), read_image(men_dir + file)), axis=0) for file in listdir(men_dir)])\n",
    "\t\tnew_women = np.array([np.concatenate((np.asarray([num]), read_image(women_dir + file)), axis=0) for file in listdir(women_dir)])\n",
    "\t\tarray = np.concatenate((array, new_men, new_women), axis=0)\n",
    "\treturn array\n",
    "\n",
    "dataset = read_images('../clean_reduced_dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation = train_test_split(dataset, test_size=0.001)\n",
    "# X = train[:, 1:]\n",
    "# y = train[:, 0]\n",
    "# X_val = validation[:, 1:]\n",
    "# y_val = validation[:, 0]\n",
    "X = dataset[:, 1:]\n",
    "y = dataset[:, 0]\n",
    "X_val = X[0:3, :]\n",
    "y_val = y[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "from itertools import chain,cycle\n",
    "def display_side_by_side(*args,titles=cycle([''])):\n",
    "    html_str=''\n",
    "    for df,title in zip(args, chain(titles,cycle(['</br>'])) ):\n",
    "        # html_str+='<th style=\"text-align:center\"><td style=\"vertical-align:top\">'\n",
    "        # html_str+=f'<h2 style=\"text-align: center;\">{title}</h2>'\n",
    "        html_str+=df.to_html().replace('table','table style=\"display:inline\"')\n",
    "        # html_str+='</td></th>'\n",
    "    display_html(html_str,raw=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "John's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_arr = np.zeros((6,6))\n",
    "def model_prediction(model, x_training, y_training, x_validation, y_validation, weights=None):\n",
    "\tmodel.fit(x_training, y_training, sample_weight=weights)\n",
    "\tprediction_training = np.array(np.round(model.predict(x_training)), dtype=np.int8)\n",
    "\tprediction_validation = np.array(np.round(model.predict(x_validation)), dtype=np.int8)\n",
    "\tacc_training = accuracy_score(y_training, prediction_training)\n",
    "\tacc_validation = accuracy_score(y_validation, prediction_validation)\n",
    "\n",
    "\tconfusion_matrix_training = confusion_matrix(y_training, prediction_training)\n",
    "\tconfusion_matrix_validation = confusion_matrix(y_validation, prediction_validation)\n",
    "\t# print(\"Confusion Matrix Training: \\n\", confusion_matrix_training)\n",
    "\tdisplay_side_by_side(pd.DataFrame(confusion_matrix_training), pd.DataFrame(confusion_matrix_validation))\n",
    "\t# print(\"Confusion Matrix Validation: \\n\", confusion_matrix_validation)\n",
    "\tprint(\"Accuracuy Score Training: \", acc_training)\n",
    "\tprint(\"Accuracy Score Validation: \",acc_validation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=30).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):\n",
    "    train, validation = train_test_split(dataset, test_size=0.1)\n",
    "    X = train[:, 1:]\n",
    "    y = train[:, 0]\n",
    "    # X = np.concatenate((X, X[(y == 3), :]), axis=0)\n",
    "    # y = np.concatenate((y, y[(y == 3)]), axis=0)\n",
    "    X_val = validation[:, 1:]\n",
    "    y_val = validation[:, 0]\n",
    "    print(f'Run no.{i}:')\n",
    "    pca = PCA(n_components=30).fit(X)\n",
    "    model = svm.SVC(C=10)\n",
    "    w = np.ones(X.shape[0])\n",
    "    w[y == 3] = 10\n",
    "    model_prediction(model, pca.transform(X=X), y, pca.transform(X=X_val), y_val, w)\n",
    "    # m = preprocessing.StandardScaler().fit(X)\n",
    "    # X, X_val = m.transform(X),m.transform(X_val)\n",
    "# print('Random forest classifier')\n",
    "# for i in range(1, 6):\n",
    "# \tprint(f'Run no.{i}:')\n",
    "# \tmodel_prediction(RandomForestClassifier(n_estimators = 500, min_samples_split=10, max_features=None), pca.transform(X), y, pca.transform(X_val), y_val)\n",
    "# model_prediction(RandomForestClassifier(n_estimators = 500, min_samples_split=10, max_features=None), pca.transform(X), y, pca.transform(X_val), y_val)\n",
    "# print('SVC')\n",
    "# model_prediction(svm.SVC(), pca.transform(X), y, pca.transform(X_val), y_val)\n",
    "# print('NuSVC')\n",
    "# model_prediction(svm.NuSVC(nu=0.1), pca.transform(X), y, pca.transform(X_val), y_val)\n",
    "# print('SVC with C=10')\n",
    "# model_prediction(svm.SVC(C=10), pca.transform(X), y, pca.transform(X_val), y_val)\n",
    "# print('Random forest regressor')\n",
    "# model_prediction(RandomForestRegressor(n_estimators = 500, min_samples_split=10, max_features=None), pca.transform(X), y, pca.transform(X_val), y_val)\n",
    "\n",
    "# print('KNN')\n",
    "# model_prediction(KNeighborsClassifier(n_neighbors=6), pca.transform(X), y, pca.transform(X_val), y_val)\n",
    "# dataset = np.array([])\n",
    "# for filename in sorted(glob.glob('../clean_reduced_dataset/men/*/*.JPG')):\n",
    "# \timg = cv2.imread(filename)\n",
    "# \timg = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "# \tdx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=7)\n",
    "# \tdy = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=7)\n",
    "# \timg_masked = np.linalg.norm(np.array([dx,dy]),axis=0)\n",
    "# \timg_masked *= 255.0/np.max(img_masked)\n",
    "# \timg_masked = np.asarray(cv2.threshold(img_masked,thresh=100,maxval=255,type=cv2.THRESH_BINARY)[1],dtype=np.uint8)\n",
    "\n",
    "# \tctrs, _ = cv2.findContours(img_masked,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "# \tmax_ctr = max(ctrs,key=cv2.contourArea)\n",
    "# \tcontour = np.zeros(img_masked.shape)\n",
    "# \tcv2.drawContours(contour,max_ctr,-1,(255,0,0),1)\n",
    "# \t# print(cv2.contourArea(max_ctr))\n",
    "# \t# histogramV = np.mean(np.sum(img_masked,axis=0))\n",
    "# \tlabel = int(filename[29])\n",
    "# \tarray = np.array([label,cv2.contourArea(max_ctr)])\n",
    "# \tdataset = np.concatenate((dataset,array),axis=0)\n",
    "# dataset = dataset.reshape(-1,2)\n",
    "# cmap = colors.ListedColormap(['red','green','blue','yellow','cyan','pink'])\n",
    "# plt.scatter(dataset[:,0],dataset[:,1])\n",
    "# train, validation = train_test_split(dataset, test_size=0.1)\n",
    "# X = train[:, 1:]\n",
    "# y = train[:, 0]\n",
    "# X_val = validation[:, 1:]\n",
    "# y_val = validation[:, 0]\n",
    "# print('KNN')\n",
    "# model_prediction(KNeighborsClassifier(n_neighbors=6), X, y, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10, 50, 2):\n",
    "\tprint('*'* 20)\n",
    "\tprint(f'PCA {i} components')\n",
    "\tpca = PCA(n_components=i).fit(X)\n",
    "\tprint('SVM')\n",
    "\tmodel_prediction(svm.SVC(), pca.transform(X), y, pca.transform(X_val), y_val)\n",
    "\t# print('KNN, N=5')\n",
    "\t# model_prediction(KNeighborsClassifier(n_neighbors=5), pca.transform(X), y, pca.transform(X_val), y_val)\n",
    "\tprint('*'* 20)\n",
    "\tprint('\\n\\n')\n",
    "# 78.88%  85%  84.44%  77.77%  79.44%  with hull\n",
    "# 74.44%  75.55%  77.22%  82.22%  81.66%  without hull"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pca, open('pca.pkl', 'wb'))\n",
    "pickle.dump(model, open('model.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
