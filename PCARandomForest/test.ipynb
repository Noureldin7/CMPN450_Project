{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import statsmodels.api as sm\n",
    "# import seaborn as sns\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import cv2\n",
    "from random import randint\n",
    "# from PIL import Image\n",
    "from os import listdir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compress images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compress_image(path : str):\n",
    "# \tim = Image.open(path)\n",
    "# \tim.thumbnail((500, 500), Image.LANCZOS)\n",
    "# \tim.save(path.replace('dataset', 'reduced_dataset'))\n",
    "\n",
    "# def compress_dataset(path : str):\n",
    "# \tfor num in range(0,6):\n",
    "# \t\tmen_dir = path + f'men/{num}/'\n",
    "# \t\twomen_dir = path + f'Women/{num}/'\n",
    "# \t\tfor file in listdir(men_dir):\n",
    "# \t\t\tcompress_image(men_dir + file)\n",
    "# \t\tfor file in listdir(women_dir):\n",
    "# \t\t\tcompress_image(women_dir + file)\n",
    "\n",
    "# compress_dataset('../../dataset/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path: str) -> np.array:\n",
    "\timg = cv2.imread(path)\n",
    "\timg = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "\timg_masked_shadow = np.bitwise_not(cv2.inRange(img,(0,0,80),(255,55,179)))\n",
    "\timg_masked_hand = cv2.inRange(img,(5,35,30),(25,255,255))\n",
    "\timg_filtered = np.bitwise_and(img_masked_shadow,img_masked_hand)\n",
    "\tarea = np.array([np.sum(img_filtered.reshape((-1))) / 255])\n",
    "\treturn np.concatenate((area, img_filtered.reshape(-1)))\n",
    "\n",
    "def read_images(directory : str) -> np.array:\n",
    "\tarray = np.array([], dtype=np.int8).reshape(0, 140502)\n",
    "\tfor num in range(0,6):\n",
    "\t\tmen_dir = directory + f'men/{num}/'\n",
    "\t\twomen_dir = directory + f'Women/{num}/'\n",
    "\t\tnew_men = np.array([np.concatenate((np.asarray([num]), read_image(men_dir + file)), axis=0) for file in listdir(men_dir)])\n",
    "\t\tnew_women = np.array([np.concatenate((np.asarray([num]), read_image(women_dir + file)), axis=0) for file in listdir(women_dir)])\n",
    "\t\tarray = np.concatenate((array, new_men, new_women), axis=0)\n",
    "\treturn array\n",
    "\n",
    "dataset = read_images('../../reduced_dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[[0,0,0], [200,20, 100]]])\n",
    "cv2.inRange(arr,(0,0,80),(255,55,179))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation = train_test_split(dataset, test_size=0.1)\n",
    "X = train[:, 1:]\n",
    "y = train[:, 0]\n",
    "X_val = validation[:, 1:]\n",
    "y_val = validation[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "from itertools import chain,cycle\n",
    "def display_side_by_side(*args,titles=cycle([''])):\n",
    "    html_str=''\n",
    "    for df,title in zip(args, chain(titles,cycle(['</br>'])) ):\n",
    "        # html_str+='<th style=\"text-align:center\"><td style=\"vertical-align:top\">'\n",
    "        # html_str+=f'<h2 style=\"text-align: center;\">{title}</h2>'\n",
    "        html_str+=df.to_html().replace('table','table style=\"display:inline\"')\n",
    "        # html_str+='</td></th>'\n",
    "    display_html(html_str,raw=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "John's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_arr = np.zeros((6,6))\n",
    "def model_prediction(model, x_training, y_training, x_validation, y_validation):\n",
    "\tmodel.fit(x_training, y_training)\n",
    "\t\n",
    "\tprediction_training = np.array(np.round(model.predict(x_training)), dtype=np.int8)\n",
    "\tprediction_validation = np.array(np.round(model.predict(x_validation)), dtype=np.int8)\n",
    "\t\n",
    "\tacc_training = accuracy_score(y_training, prediction_training)\n",
    "\tacc_validation = accuracy_score(y_validation, prediction_validation)\n",
    "\n",
    "\tconfusion_matrix_training = confusion_matrix(y_training, prediction_training)\n",
    "\tconfusion_matrix_validation = confusion_matrix(y_validation, prediction_validation)\n",
    "\t# print(\"Confusion Matrix Training: \\n\", confusion_matrix_training)\n",
    "\tdisplay_side_by_side(pd.DataFrame(confusion_matrix_training), pd.DataFrame(confusion_matrix_validation))\n",
    "\t# print(\"Confusion Matrix Validation: \\n\", confusion_matrix_validation)\n",
    "\tprint(\"Accuracuy Score Training: \", acc_training)\n",
    "\tprint(\"Accuracy Score Validation: \",acc_validation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=30).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random forest classifier')\n",
    "for i in range(1, 11):\n",
    "\tprint(f'Run no.{i}:')\n",
    "\tmodel_prediction(RandomForestClassifier(n_estimators = 10, min_samples_split=10, max_features=None), pca.transform(X), y, pca.transform(X_val), y_val)\n",
    "\n",
    "# print('Random forest regressor')\n",
    "# model_prediction(RandomForestRegressor(n_estimators = 500, min_samples_split=10, max_features=None), pca.transform(X), y, pca.transform(X_val), y_val)\n",
    "\n",
    "\n",
    "# print('KNN')\n",
    "# model_prediction(KNeighborsClassifier(n_neighbors=3), pca.transform(X), y, pca.transform(X_val), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10, 50, 2):\n",
    "\tprint('*'* 20)\n",
    "\tprint(f'PCA {i} components')\n",
    "\tpca = PCA(n_components=i).fit(X)\n",
    "\tprint('Random forest')\n",
    "\tmodel_prediction(RandomForestClassifier(n_estimators = 500, min_samples_split=10, max_features=None), pca.transform(X), y, pca.transform(X_val), y_val)\n",
    "\t# print('KNN, N=5')\n",
    "\t# model_prediction(KNeighborsClassifier(n_neighbors=5), pca.transform(X), y, pca.transform(X_val), y_val)\n",
    "\tprint('*'* 20)\n",
    "\tprint('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
